{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yey\n"
     ]
    }
   ],
   "source": [
    "# @version : 05/2023\n",
    "# @author : grafika_jati\n",
    "# LiDAR cover contaminant classification using 2D CNN. Input is 2D spherical image\n",
    "\n",
    "# Split train and test from dataset taken by # B. Schlager, T. Goelles, S. Muckenhuber and D. Watzenig, \"Contaminations on Lidar Sensor Covers: Performance Degradation Including Fault Detection and Modeling as Potential Applications,\" in IEEE Open Journal of Intelligent Transportation Systems, vol. 3, pp. 738-747, 2022, doi: 10.1109/OJITS.2022.3214094.\n",
    "\n",
    "# Train : exp 1,2,3,4\n",
    "# Test : exp 5\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import math\n",
    "import time as ti\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  dev = \"cuda:3\"\n",
    "  print(\"yey\")\n",
    "device = torch.device(dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to plot confusion matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    # plt.savefig('2D_spherical_proj_class_norm_per_exp_train_test_IRA_30x70_Conf/all-exp-'+'2D_spherical_proj_class_norm_per_exp_train_test-IRA-30x70'+'.png')\n",
    "\n",
    "    plt.savefig('2D_spherical_proj_class_norm_per_exp_train_test_IRA_9x16_Conf/all-exp-'+'2D_spherical_proj_class_norm_per_exp_train_test-IRA-9x16'+'.png')\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relevant variables for the ML task\n",
    "batch_size = 32\n",
    "num_classes = 6\n",
    "learning_rate = 0.01 #0.001 #0.01\n",
    "num_epochs = 150 #150 # 100 #50 #10 #30\n",
    "\n",
    "\n",
    "# BEST PARAM\n",
    "# batch_size = 32\n",
    "# num_classes = 10\n",
    "# learning_rate = 0.001\n",
    "# num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "# df = pd.read_json('../get_2D_spherical_Norm_per_exp_train_test/lidar_norm_train_test_2d_spherical_10class_DRA_30x70.json')\n",
    "# df = pd.read_json('../get_2D_spherical_Norm_per_exp_train_test/lidar_norm_train_test_2d_spherical_10class_DRA_9x16.json')\n",
    "\n",
    "df = pd.read_json('../get_2D_spherical_Norm_per_exp_train_test/lidar_norm_train_test_2d_spherical_10class_norm_DRA_9x16.json')\n",
    "\n",
    "\n",
    "df_add = df\n",
    "\n",
    "#get data class=ref without cover\n",
    "df_no_cover =df_add[df_add['class'] == 'no_cover']\n",
    "df_ref_train = df_no_cover.sample(frac=0.80,random_state=1)\n",
    "df_ref_test = df_no_cover.drop(df_ref_train.index)\n",
    "\n",
    "\n",
    "#get data class=ref with cover\n",
    "df_cover =df_add[df_add['class'] == 'cover']\n",
    "df_ref_wh_train = df_cover.sample(frac=0.80,random_state=1)\n",
    "df_ref_wh_test = df_cover.drop(df_ref_wh_train.index)\n",
    "\n",
    "#get data class oil, foam, dirt, water from exp 1,2,3,4\n",
    "#get training data\n",
    "df_water_all=df_add[df_add['class'] == 'water']\n",
    "df_water_1=df_water_all[df_water_all['exp'].isin([1])] \n",
    "df_water_2=df_water_all[df_water_all['exp'].isin([2])] \n",
    "df_water_3=df_water_all[df_water_all['exp'].isin([3])] \n",
    "df_water_4=df_water_all[df_water_all['exp'].isin([4])] \n",
    "df_water_5=df_water_all[df_water_all['exp'].isin([5])] \n",
    "\n",
    "\n",
    "df_oil_all=df_add[df_add['class'] == 'oil']\n",
    "df_oil_1=df_oil_all[df_oil_all['exp'].isin([1])] \n",
    "df_oil_2=df_oil_all[df_oil_all['exp'].isin([2])] \n",
    "df_oil_3=df_oil_all[df_oil_all['exp'].isin([3])] \n",
    "df_oil_4=df_oil_all[df_oil_all['exp'].isin([4])] \n",
    "df_oil_5=df_oil_all[df_oil_all['exp'].isin([5])] \n",
    "\n",
    "df_foam_all=df_add[df_add['class'] == 'foam']\n",
    "df_foam_1=df_foam_all[df_foam_all['exp'].isin([1])] \n",
    "df_foam_2=df_foam_all[df_foam_all['exp'].isin([2])] \n",
    "df_foam_3=df_foam_all[df_foam_all['exp'].isin([3])] \n",
    "df_foam_4=df_foam_all[df_foam_all['exp'].isin([4])] \n",
    "df_foam_5=df_foam_all[df_foam_all['exp'].isin([5])] \n",
    "\n",
    "df_dirt_all=df_add[df_add['class'] == 'dirt']\n",
    "df_dirt_1=df_dirt_all[df_dirt_all['exp'].isin([1])] \n",
    "df_dirt_2=df_dirt_all[df_dirt_all['exp'].isin([2])] \n",
    "df_dirt_3=df_dirt_all[df_dirt_all['exp'].isin([3])] \n",
    "df_dirt_4=df_dirt_all[df_dirt_all['exp'].isin([4])] \n",
    "df_dirt_5=df_dirt_all[df_dirt_all['exp'].isin([5])] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatChannels(x):\n",
    "    size = x.size()\n",
    "    # print(\"flatChannels\")\n",
    "    # print(size)\n",
    "    return x.view(size[0],size[1],size[2]*size[3])\n",
    "\n",
    "def globalAvgPool2D(x):        \n",
    "    return flatChannels(x).mean(dim=-1)\n",
    "\n",
    "def globalMaxPool2D(x):\n",
    "    return flatChannels(x).max(dim=-1)\n",
    "    \n",
    "class Unit(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        super(Unit,self).__init__()\n",
    "        \n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels,kernel_size=3,out_channels=out_channels,stride=1,padding=1) # \n",
    "        self.bn = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,input):\n",
    "        output = self.conv(input)\n",
    "        # output = self.bn(output)\n",
    "        output = self.relu(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super(Net,self).__init__()\n",
    "\n",
    "        #Create 14 layers of the unit with max pooling in between\n",
    "        self.unit0 = Unit(in_channels=3,out_channels=16)\n",
    "        self.unit15 = Unit(in_channels=16,out_channels=32)\n",
    "        self.unit16 = Unit(in_channels=32,out_channels=64)\n",
    "      \n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=4)\n",
    "        \n",
    "        #Add all the units into the Sequential layer in exact order\n",
    "        \n",
    "        self.net = nn.Sequential(self.unit0, self.unit15, self.unit16) #BEST\n",
    "        self.fc = nn.Linear(in_features=64,out_features=num_classes) #BEST\n",
    "      \n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.net(input)\n",
    "        output = globalAvgPool2D(output) \n",
    "        output = self.fc(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(num_epochs): #Training your network\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs): # loop over the dataset multiple times\n",
    "   \n",
    "        train_acc = 0.0\n",
    "        train_loss = 0.0\n",
    "     \n",
    "        for i, data in enumerate(list_train_tensor, 0):\n",
    "     \n",
    "            #get the input; data is a list of [input, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device=device), labels.to(device=device)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "           # forward pass \n",
    "            outputs = net(inputs)\n",
    "    \n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # backward and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, prediction = torch.max(outputs.data, 1)\n",
    "      \n",
    "            train_acc += torch.sum(prediction == labels.data)\n",
    "\n",
    "        #Compute the average acc and loss over all 50000 training images\n",
    "        train_acc = train_acc / df_train_X_tensor.size()[0]\n",
    "        train_loss = train_loss / df_train_X_tensor.size()[0]\n",
    "\n",
    "         # Print the metrics\n",
    "        print(\"Epoch {}, Train Accuracy: {} , Train Loss: {}\".format(epoch, train_acc, train_loss))\n",
    "            # print statistics\n",
    "        losses.append(loss.data.cpu())\n",
    "      \n",
    "    plt.plot(losses, label ='Training loss')\n",
    "    plt.show()\n",
    "    print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2742189/851170086.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_A_train = df_A_train.append(df)\n",
      "/tmp/ipykernel_2742189/851170086.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_A_train = df_A_train.append(df)\n",
      "/tmp/ipykernel_2742189/851170086.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_A_train = df_A_train.append(df)\n",
      "/tmp/ipykernel_2742189/851170086.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_A_train = df_A_train.append(df)\n",
      "/tmp/ipykernel_2742189/851170086.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_A_train = df_A_train.append(df)\n",
      "/tmp/ipykernel_2742189/851170086.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_A_train = df_A_train.append(df)\n",
      "/tmp/ipykernel_2742189/851170086.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_A_train = df_A_train.append(df)\n",
      "/tmp/ipykernel_2742189/851170086.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_A_train = df_A_train.append(df)\n",
      "/tmp/ipykernel_2742189/851170086.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_A_train = df_A_train.append(df)\n",
      "/tmp/ipykernel_2742189/851170086.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_A_train = df_A_train.append(df)\n",
      "/tmp/ipykernel_2742189/851170086.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_A_train = df_A_train.append(df)\n",
      "/tmp/ipykernel_2742189/851170086.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_A_train = df_A_train.append(df)\n",
      "/tmp/ipykernel_2742189/851170086.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_A_train = df_A_train.append(df)\n",
      "/tmp/ipykernel_2742189/851170086.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_A_train = df_A_train.append(df)\n",
      "/tmp/ipykernel_2742189/851170086.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_A_train = df_A_train.append(df)\n",
      "/tmp/ipykernel_2742189/851170086.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_A_train = df_A_train.append(df)\n",
      "/tmp/ipykernel_2742189/851170086.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_A_train = df_A_train.append(df)\n",
      "/tmp/ipykernel_2742189/851170086.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_A_train = df_A_train.append(df)\n",
      "/tmp/ipykernel_2742189/851170086.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_A_test = df_A_test.append(df)\n",
      "/tmp/ipykernel_2742189/851170086.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_A_test = df_A_test.append(df)\n",
      "/tmp/ipykernel_2742189/851170086.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_A_test = df_A_test.append(df)\n",
      "/tmp/ipykernel_2742189/851170086.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_A_test = df_A_test.append(df)\n",
      "/tmp/ipykernel_2742189/851170086.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_A_test = df_A_test.append(df)\n",
      "/tmp/ipykernel_2742189/851170086.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_A_test = df_A_test.append(df)\n"
     ]
    }
   ],
   "source": [
    "#Split dataset for training and testing\n",
    "frame_A_train = [df_ref_train, df_ref_wh_train, df_water_1, df_water_2, df_water_3, df_water_4, df_oil_1, df_oil_2, df_oil_3, df_oil_4, df_foam_1, df_foam_2, df_foam_3, df_foam_4,df_dirt_1, df_dirt_2, df_dirt_3, df_dirt_4]\n",
    "\n",
    "df_A_train = pd.DataFrame()\n",
    "\n",
    "for df in frame_A_train:\n",
    "    df_A_train = df_A_train.append(df)\n",
    "\n",
    "frame_A_test = [df_ref_test, df_ref_wh_test, df_water_5, df_oil_5, df_foam_5, df_dirt_5]\n",
    "\n",
    "df_A_test = pd.DataFrame()\n",
    "\n",
    "for df in frame_A_test:\n",
    "    df_A_test = df_A_test.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data train and data test\n",
    "\n",
    "df_A_train_clean =  df_A_train.drop('exp', axis=1)\n",
    "df_A_test_clean =  df_A_test.drop('exp', axis=1)\n",
    "\n",
    "df_A_train_clean = df_A_train_clean.sample(frac = 1,random_state=1)\n",
    "df_A_test_clean = df_A_test_clean.sample(frac = 1,random_state=1)\n",
    "\n",
    "df_A_train_X = df_A_train_clean.drop('class', axis=1)\n",
    "df_A_train_Y = df_A_train_clean['class']\n",
    "\n",
    "df_A_test_X = df_A_test_clean.drop('class', axis=1)\n",
    "df_A_test_Y = df_A_test_clean['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_X = df_A_train_X\n",
    "df_train_Y = df_A_train_Y\n",
    "\n",
    "df_test_X = df_A_test_X\n",
    "df_test_Y = df_A_test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for FOLD: \n",
      "Epoch 0, Train Accuracy: 0.28287172317504883 , Train Loss: 0.05101737138820483\n",
      "Epoch 1, Train Accuracy: 0.6706103682518005 , Train Loss: 0.027142645202679287\n",
      "Epoch 2, Train Accuracy: 0.8552029728889465 , Train Loss: 0.01215182938749478\n",
      "Epoch 3, Train Accuracy: 0.889620840549469 , Train Loss: 0.00888135351649325\n",
      "Epoch 4, Train Accuracy: 0.9244419932365417 , Train Loss: 0.006374086649013113\n",
      "Epoch 5, Train Accuracy: 0.9481042623519897 , Train Loss: 0.0047927148419533265\n",
      "Epoch 6, Train Accuracy: 0.9611454010009766 , Train Loss: 0.003753834417323715\n",
      "Epoch 7, Train Accuracy: 0.9693465828895569 , Train Loss: 0.0029311307447252013\n",
      "Epoch 8, Train Accuracy: 0.9725732207298279 , Train Loss: 0.00275609693722862\n",
      "Epoch 9, Train Accuracy: 0.9702876806259155 , Train Loss: 0.003024294905556838\n",
      "Epoch 10, Train Accuracy: 0.9739176630973816 , Train Loss: 0.0027284467254201127\n",
      "Epoch 11, Train Accuracy: 0.976606547832489 , Train Loss: 0.0024338722610648326\n",
      "Epoch 12, Train Accuracy: 0.9783543348312378 , Train Loss: 0.0022075706855292526\n",
      "Epoch 13, Train Accuracy: 0.9790265560150146 , Train Loss: 0.002212482354762476\n",
      "Epoch 14, Train Accuracy: 0.9810432195663452 , Train Loss: 0.0021051302812256033\n",
      "Epoch 15, Train Accuracy: 0.9810432195663452 , Train Loss: 0.0020603942634744663\n",
      "Epoch 16, Train Accuracy: 0.9815810322761536 , Train Loss: 0.0020678201431598093\n",
      "Epoch 17, Train Accuracy: 0.9838665723800659 , Train Loss: 0.0018473195861679439\n",
      "Epoch 18, Train Accuracy: 0.9840010404586792 , Train Loss: 0.0017747433094092917\n",
      "Epoch 19, Train Accuracy: 0.9849421381950378 , Train Loss: 0.0017177325274962952\n",
      "Epoch 20, Train Accuracy: 0.9854799509048462 , Train Loss: 0.0016777029070092536\n",
      "Epoch 21, Train Accuracy: 0.9856143593788147 , Train Loss: 0.0016746963186969098\n",
      "Epoch 22, Train Accuracy: 0.9858832359313965 , Train Loss: 0.001618635254552346\n",
      "Epoch 23, Train Accuracy: 0.9862865805625916 , Train Loss: 0.0015761799859745104\n",
      "Epoch 24, Train Accuracy: 0.9862865805625916 , Train Loss: 0.0015653369193133488\n",
      "Epoch 25, Train Accuracy: 0.9862865805625916 , Train Loss: 0.0015355411299412811\n",
      "Epoch 26, Train Accuracy: 0.9865554571151733 , Train Loss: 0.0015106904791057276\n",
      "Epoch 27, Train Accuracy: 0.9866899251937866 , Train Loss: 0.001490678877702334\n",
      "Epoch 28, Train Accuracy: 0.9873621463775635 , Train Loss: 0.0014783996275281666\n",
      "Epoch 29, Train Accuracy: 0.9872276782989502 , Train Loss: 0.0014662106376761481\n",
      "Epoch 30, Train Accuracy: 0.9872276782989502 , Train Loss: 0.0014527787765388862\n",
      "Epoch 31, Train Accuracy: 0.9880343675613403 , Train Loss: 0.0014392239288120794\n",
      "Epoch 32, Train Accuracy: 0.9880343675613403 , Train Loss: 0.0014264248822460491\n",
      "Epoch 33, Train Accuracy: 0.9881688356399536 , Train Loss: 0.0014171286738671976\n",
      "Epoch 34, Train Accuracy: 0.9880343675613403 , Train Loss: 0.0014115652312453497\n",
      "Epoch 35, Train Accuracy: 0.9880343675613403 , Train Loss: 0.001399138582260647\n",
      "Epoch 36, Train Accuracy: 0.9881688356399536 , Train Loss: 0.001390630892631251\n",
      "Epoch 37, Train Accuracy: 0.9883032441139221 , Train Loss: 0.0013872940999199192\n",
      "Epoch 38, Train Accuracy: 0.9885721802711487 , Train Loss: 0.0013782875893556025\n",
      "Epoch 39, Train Accuracy: 0.9885721802711487 , Train Loss: 0.0013711812504852438\n",
      "Epoch 40, Train Accuracy: 0.9885721802711487 , Train Loss: 0.0013660556725040404\n",
      "Epoch 41, Train Accuracy: 0.9885721802711487 , Train Loss: 0.0013603192254214524\n",
      "Epoch 42, Train Accuracy: 0.9887065887451172 , Train Loss: 0.0013513723212079168\n",
      "Epoch 43, Train Accuracy: 0.9885721802711487 , Train Loss: 0.0013470302696558154\n",
      "Epoch 44, Train Accuracy: 0.9887065887451172 , Train Loss: 0.001338969669916133\n",
      "Epoch 45, Train Accuracy: 0.988975465297699 , Train Loss: 0.0013316942421888718\n",
      "Epoch 46, Train Accuracy: 0.988975465297699 , Train Loss: 0.0013262003312630765\n",
      "Epoch 47, Train Accuracy: 0.9891099333763123 , Train Loss: 0.0013230338516946518\n",
      "Epoch 48, Train Accuracy: 0.9892444014549255 , Train Loss: 0.001315600339668678\n",
      "Epoch 49, Train Accuracy: 0.989378809928894 , Train Loss: 0.0013077999278915528\n",
      "Epoch 50, Train Accuracy: 0.9896476864814758 , Train Loss: 0.0013007503214176282\n",
      "Epoch 51, Train Accuracy: 0.9895132780075073 , Train Loss: 0.0012950636951782337\n",
      "Epoch 52, Train Accuracy: 0.9895132780075073 , Train Loss: 0.0012907777425466677\n",
      "Epoch 53, Train Accuracy: 0.9896476864814758 , Train Loss: 0.0012871398563960301\n",
      "Epoch 54, Train Accuracy: 0.9896476864814758 , Train Loss: 0.0012803076839351334\n",
      "Epoch 55, Train Accuracy: 0.9896476864814758 , Train Loss: 0.0012761054385684353\n",
      "Epoch 56, Train Accuracy: 0.9895132780075073 , Train Loss: 0.0012747502567127104\n",
      "Epoch 57, Train Accuracy: 0.9895132780075073 , Train Loss: 0.0012628939482938117\n",
      "Epoch 58, Train Accuracy: 0.989378809928894 , Train Loss: 0.0012598898192668802\n",
      "Epoch 59, Train Accuracy: 0.9895132780075073 , Train Loss: 0.001255320386147103\n",
      "Epoch 60, Train Accuracy: 0.9895132780075073 , Train Loss: 0.0012515808566411193\n",
      "Epoch 61, Train Accuracy: 0.989378809928894 , Train Loss: 0.0012475611471339887\n",
      "Epoch 62, Train Accuracy: 0.9892444014549255 , Train Loss: 0.0012441400762876027\n",
      "Epoch 63, Train Accuracy: 0.989378809928894 , Train Loss: 0.001240509488374387\n",
      "Epoch 64, Train Accuracy: 0.989378809928894 , Train Loss: 0.0012352196595805083\n",
      "Epoch 65, Train Accuracy: 0.9895132780075073 , Train Loss: 0.0012305880788971379\n",
      "Epoch 66, Train Accuracy: 0.9895132780075073 , Train Loss: 0.0012262796101368324\n",
      "Epoch 67, Train Accuracy: 0.9895132780075073 , Train Loss: 0.0012205854778560056\n",
      "Epoch 68, Train Accuracy: 0.9895132780075073 , Train Loss: 0.0012163082181214865\n",
      "Epoch 69, Train Accuracy: 0.9897821545600891 , Train Loss: 0.0012126699814336405\n",
      "Epoch 70, Train Accuracy: 0.9899166226387024 , Train Loss: 0.0012069548486261965\n",
      "Epoch 71, Train Accuracy: 0.9899166226387024 , Train Loss: 0.0012047309742303706\n",
      "Epoch 72, Train Accuracy: 0.9900510311126709 , Train Loss: 0.0012010864672987226\n",
      "Epoch 73, Train Accuracy: 0.9899166226387024 , Train Loss: 0.0011979420764498404\n",
      "Epoch 74, Train Accuracy: 0.9897821545600891 , Train Loss: 0.001193151494227555\n",
      "Epoch 75, Train Accuracy: 0.9899166226387024 , Train Loss: 0.001189339105692343\n",
      "Epoch 76, Train Accuracy: 0.9897821545600891 , Train Loss: 0.001186256195769692\n",
      "Epoch 77, Train Accuracy: 0.9897821545600891 , Train Loss: 0.0011814889674697\n",
      "Epoch 78, Train Accuracy: 0.9897821545600891 , Train Loss: 0.0011785562598805048\n",
      "Epoch 79, Train Accuracy: 0.9896476864814758 , Train Loss: 0.0011753698333339519\n",
      "Epoch 80, Train Accuracy: 0.9896476864814758 , Train Loss: 0.0011636633078997973\n",
      "Epoch 81, Train Accuracy: 0.9896476864814758 , Train Loss: 0.0011608373944335332\n",
      "Epoch 82, Train Accuracy: 0.9896476864814758 , Train Loss: 0.0011574383864661818\n",
      "Epoch 83, Train Accuracy: 0.9899166226387024 , Train Loss: 0.0011502433070351634\n",
      "Epoch 84, Train Accuracy: 0.9899166226387024 , Train Loss: 0.0011432728380864848\n",
      "Epoch 85, Train Accuracy: 0.9899166226387024 , Train Loss: 0.0011386418578153716\n",
      "Epoch 86, Train Accuracy: 0.9897821545600891 , Train Loss: 0.0011343696034231939\n",
      "Epoch 87, Train Accuracy: 0.9897821545600891 , Train Loss: 0.001123566297383773\n",
      "Epoch 88, Train Accuracy: 0.9899166226387024 , Train Loss: 0.0011175976538299185\n",
      "Epoch 89, Train Accuracy: 0.9903199076652527 , Train Loss: 0.0011129791978863098\n",
      "Epoch 90, Train Accuracy: 0.990454375743866 , Train Loss: 0.0011057007482361012\n",
      "Epoch 91, Train Accuracy: 0.990454375743866 , Train Loss: 0.0010988135698799728\n",
      "Epoch 92, Train Accuracy: 0.9905888438224792 , Train Loss: 0.0010900064483903495\n",
      "Epoch 93, Train Accuracy: 0.9907232522964478 , Train Loss: 0.0010866581704498213\n",
      "Epoch 94, Train Accuracy: 0.990857720375061 , Train Loss: 0.001077154834625046\n",
      "Epoch 95, Train Accuracy: 0.990857720375061 , Train Loss: 0.0010749502388757192\n",
      "Epoch 96, Train Accuracy: 0.990857720375061 , Train Loss: 0.0010640392993742354\n",
      "Epoch 97, Train Accuracy: 0.990857720375061 , Train Loss: 0.0010691422257635894\n",
      "Epoch 98, Train Accuracy: 0.9907232522964478 , Train Loss: 0.0010680883792791196\n",
      "Epoch 99, Train Accuracy: 0.9911265969276428 , Train Loss: 0.0010660258149413273\n",
      "Epoch 100, Train Accuracy: 0.9909921884536743 , Train Loss: 0.0010651070739706174\n",
      "Epoch 101, Train Accuracy: 0.9909921884536743 , Train Loss: 0.0010556931705074473\n",
      "Epoch 102, Train Accuracy: 0.9911265969276428 , Train Loss: 0.0010468675161149172\n",
      "Epoch 103, Train Accuracy: 0.9911265969276428 , Train Loss: 0.0010427663213918104\n",
      "Epoch 104, Train Accuracy: 0.9911265969276428 , Train Loss: 0.0010381829763163079\n",
      "Epoch 105, Train Accuracy: 0.9911265969276428 , Train Loss: 0.0010324323379899993\n",
      "Epoch 106, Train Accuracy: 0.9912610650062561 , Train Loss: 0.001023212233259668\n",
      "Epoch 107, Train Accuracy: 0.9912610650062561 , Train Loss: 0.0010166167485020964\n",
      "Epoch 108, Train Accuracy: 0.9913954734802246 , Train Loss: 0.0010063240756086017\n",
      "Epoch 109, Train Accuracy: 0.9912610650062561 , Train Loss: 0.0010047960236009537\n",
      "Epoch 110, Train Accuracy: 0.9912610650062561 , Train Loss: 0.0010015733778851973\n",
      "Epoch 111, Train Accuracy: 0.9912610650062561 , Train Loss: 0.0009989862076712583\n",
      "Epoch 112, Train Accuracy: 0.9912610650062561 , Train Loss: 0.0010017071142589859\n",
      "Epoch 113, Train Accuracy: 0.9913954734802246 , Train Loss: 0.0009808444212619405\n",
      "Epoch 114, Train Accuracy: 0.9913954734802246 , Train Loss: 0.0009805717860316844\n",
      "Epoch 115, Train Accuracy: 0.9913954734802246 , Train Loss: 0.0009704574495552718\n",
      "Epoch 116, Train Accuracy: 0.991933286190033 , Train Loss: 0.0009634921993835461\n",
      "Epoch 117, Train Accuracy: 0.9915299415588379 , Train Loss: 0.0009530778032172603\n",
      "Epoch 118, Train Accuracy: 0.9916644096374512 , Train Loss: 0.0009473659831323841\n",
      "Epoch 119, Train Accuracy: 0.9916644096374512 , Train Loss: 0.0009382526608411927\n",
      "Epoch 120, Train Accuracy: 0.9915299415588379 , Train Loss: 0.000952778227340418\n",
      "Epoch 121, Train Accuracy: 0.9913954734802246 , Train Loss: 0.0009711053180143324\n",
      "Epoch 122, Train Accuracy: 0.9915299415588379 , Train Loss: 0.0009505897542249457\n",
      "Epoch 123, Train Accuracy: 0.9917988181114197 , Train Loss: 0.0009304638029443404\n",
      "Epoch 124, Train Accuracy: 0.9917988181114197 , Train Loss: 0.0009397915185869399\n",
      "Epoch 125, Train Accuracy: 0.991933286190033 , Train Loss: 0.0009196691174141118\n",
      "Epoch 126, Train Accuracy: 0.9920676946640015 , Train Loss: 0.0009222135674308259\n",
      "Epoch 127, Train Accuracy: 0.9920676946640015 , Train Loss: 0.0009119894489777805\n",
      "Epoch 128, Train Accuracy: 0.9920676946640015 , Train Loss: 0.0009248791061175293\n",
      "Epoch 129, Train Accuracy: 0.991933286190033 , Train Loss: 0.0009183447739622701\n",
      "Epoch 130, Train Accuracy: 0.992336630821228 , Train Loss: 0.0008984133179578316\n",
      "Epoch 131, Train Accuracy: 0.9571120738983154 , Train Loss: 0.012182936854631399\n",
      "Epoch 132, Train Accuracy: 0.9612798690795898 , Train Loss: 0.0047205893703969005\n",
      "Epoch 133, Train Accuracy: 0.9862865805625916 , Train Loss: 0.0016437640643905739\n",
      "Epoch 134, Train Accuracy: 0.9877654910087585 , Train Loss: 0.001448924996843549\n",
      "Epoch 135, Train Accuracy: 0.9884377121925354 , Train Loss: 0.001335149086140593\n",
      "Epoch 136, Train Accuracy: 0.9896476864814758 , Train Loss: 0.0012628356773072202\n",
      "Epoch 137, Train Accuracy: 0.9900510311126709 , Train Loss: 0.0012221633490830115\n",
      "Epoch 138, Train Accuracy: 0.9900510311126709 , Train Loss: 0.0011911508808009883\n",
      "Epoch 139, Train Accuracy: 0.9899166226387024 , Train Loss: 0.001167997416207388\n",
      "Epoch 140, Train Accuracy: 0.9901854991912842 , Train Loss: 0.0011465459013130876\n",
      "Epoch 141, Train Accuracy: 0.9905888438224792 , Train Loss: 0.0011354668716723252\n",
      "Epoch 142, Train Accuracy: 0.9905888438224792 , Train Loss: 0.0011180978253735197\n",
      "Epoch 143, Train Accuracy: 0.9905888438224792 , Train Loss: 0.0011015586287223837\n",
      "Epoch 144, Train Accuracy: 0.9907232522964478 , Train Loss: 0.0010874272198244752\n",
      "Epoch 145, Train Accuracy: 0.9907232522964478 , Train Loss: 0.0010710275079097132\n",
      "Epoch 146, Train Accuracy: 0.9907232522964478 , Train Loss: 0.0010559756908744562\n",
      "Epoch 147, Train Accuracy: 0.9911265969276428 , Train Loss: 0.0010401164830047397\n",
      "Epoch 148, Train Accuracy: 0.9911265969276428 , Train Loss: 0.0010303783401835367\n",
      "Epoch 149, Train Accuracy: 0.9911265969276428 , Train Loss: 0.0010185325667956375\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Accuracy of the network on the 1792 test images: 97 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_train_Y = df_train_Y.map({'no_cover':0, 'cover':1, 'dirt':2, 'foam':3, 'oil':4, 'water':5})\n",
    "encoded_test_Y = df_test_Y.map({'no_cover':0, 'cover':1, 'dirt':2, 'foam':3, 'oil':4, 'water':5})\n",
    "\n",
    "Y_train_dummy=encoded_train_Y\n",
    "Y_test_dummy=encoded_test_Y\n",
    "\n",
    "\n",
    "#convert data train to tensor\n",
    "list_df_train_X = []\n",
    "for item in range(len(df_train_X['data'])):\n",
    "    list_df_train_X.append(df_train_X['data'].iloc[item])\n",
    "\n",
    "# df_A_train_X_tensor = torch.FloatTensor(list_df_A_train_X,device=device)\n",
    "df_train_X_tensor = torch.FloatTensor(list_df_train_X)\n",
    "\n",
    "#convert data test to tensor\n",
    "list_df_test_X = []\n",
    "for item in range(len(df_test_X['data'])):\n",
    "    list_df_test_X.append(df_test_X['data'].iloc[item])\n",
    "\n",
    "# df_A_test_X_tensor = torch.FloatTensor(list_df_A_test_X,device=device)\n",
    "df_test_X_tensor = torch.FloatTensor(list_df_test_X)\n",
    "\n",
    "\n",
    "# convert label to tensor\n",
    "encoded_train_Y_tensor = torch.from_numpy(Y_train_dummy.to_numpy())\n",
    "encoded_test_Y_tensor = torch.from_numpy(Y_test_dummy.to_numpy())\n",
    "\n",
    "# # get batch for each FOLD TRAINING    \n",
    "num_batches = math.ceil(df_train_X_tensor.size()[0]/batch_size)\n",
    "train_X_raw = [df_train_X_tensor[batch_size*y:batch_size*(y+1),:,:] for y in range(num_batches)]\n",
    "# print(train_X_raw[0].size())\n",
    "\n",
    "num_batches = math.ceil(encoded_train_Y_tensor.size()[0]/batch_size)\n",
    "train_Y_raw = [encoded_train_Y_tensor[batch_size*y:batch_size*(y+1)] for y in range(num_batches)]\n",
    "# print(train_Y_raw[0].size())\n",
    "\n",
    "List_train_row = len(train_X_raw)\n",
    "List_train_columns = 2\n",
    "list_train_tensor = [[ 0 for x in range(List_train_columns)] for i in range (List_train_row)]\n",
    "\n",
    "for i in range(List_train_row):\n",
    "    for j in range(List_train_columns):\n",
    "        list_train_tensor[i][0]=train_X_raw[i]\n",
    "        list_train_tensor[i][1]=train_Y_raw[i]\n",
    "\n",
    "\n",
    "# # get batch for each FOLD TESTING\n",
    "num_batches = math.ceil(df_test_X_tensor.size()[0]/batch_size)\n",
    "test_X_raw = [df_test_X_tensor[batch_size*y:batch_size*(y+1),:,:] for y in range(num_batches)]\n",
    "# print(test_X_raw[0].size())\n",
    "\n",
    "num_batches = math.ceil(encoded_test_Y_tensor.size()[0]/batch_size)\n",
    "test_Y_raw = [encoded_test_Y_tensor[batch_size*y:batch_size*(y+1)] for y in range(num_batches)]\n",
    "# print(test_Y_raw[0].size())\n",
    "\n",
    "List_test_row = len(test_X_raw)\n",
    "List_test_columns = 2\n",
    "list_test_tensor = [[ 0 for x in range(List_test_columns)] for i in range (List_test_row)]\n",
    "\n",
    "for i in range(List_test_row):\n",
    "    for j in range(List_test_columns):\n",
    "        list_test_tensor[i][0]=test_X_raw[i]\n",
    "        list_test_tensor[i][1]=test_Y_raw[i]\n",
    "\n",
    "print(\"Training for FOLD: \")\n",
    "\n",
    "#initialize the network\n",
    "net = Net(num_classes).cuda(device=device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "# optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.1)\n",
    "\n",
    "criterion = criterion.cuda(device=device)\n",
    "\n",
    "t = ti.time()\n",
    "\n",
    "train_net(num_epochs)\n",
    "\n",
    "elapsed_training = ti.time() - t\n",
    "training_time = elapsed_training\n",
    "\n",
    "#save model\n",
    "torch.save(net, \"model_2D_spherical_proj_class_norm_per_exp_train_test_IRA_9x16.pt\")\n",
    "\n",
    "class_name = ['clean', 'cover','dirt', 'foam', 'oil', 'water']\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "list_test_labels = []\n",
    "list_test_predicted = []\n",
    "\n",
    "timings_inference = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(list_test_tensor, 0):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        t = ti.time()\n",
    "        outputs = net(images)\n",
    "        elapsed_training = ti.time() - t\n",
    "        timings_inference.append(elapsed_training)\n",
    "\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        labels_cpu = labels.tolist()\n",
    "        predicted_cpu = predicted.tolist() \n",
    "        for jj in range(len(labels_cpu)):\n",
    "\n",
    "            list_test_labels.append(labels_cpu[jj])\n",
    "            list_test_predicted.append(predicted_cpu[jj])\n",
    "\n",
    "sum_syn = np.sum(timings_inference) # inference time per epoch\n",
    "mean_syn_per_instance = np.sum(timings_inference)/len(list_test_predicted) # inference time per epoch\n",
    "\n",
    "\n",
    "correct_CPU = 0\n",
    "total_CPU = 0\n",
    "list_test_labels_CPU = []\n",
    "list_test_predicted_CPU = []\n",
    "\n",
    "timings_inference_CPU = []\n",
    "\n",
    "net_CPU = net.cpu()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(list_test_tensor, 0):\n",
    "        images, labels = data\n",
    "        \n",
    "        t = ti.time()\n",
    "        outputs = net_CPU(images)\n",
    "        elapsed_training = ti.time() - t\n",
    "\n",
    "        \n",
    "        timings_inference_CPU.append(elapsed_training)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_CPU += labels.size(0)\n",
    "        correct_CPU += (predicted == labels).sum().item()\n",
    "\n",
    "        labels_cpu = labels.tolist()\n",
    "        predicted_cpu = predicted.tolist() \n",
    "        for jj in range(len(labels_cpu)):\n",
    "\n",
    "            list_test_labels_CPU.append(labels_cpu[jj])\n",
    "            list_test_predicted_CPU.append(predicted_cpu[jj])\n",
    "\n",
    "sum_syn_CPU = np.sum(timings_inference_CPU) # inference time per epoch\n",
    "mean_syn_per_instance_CPU = np.sum(timings_inference_CPU)/len(list_test_predicted_CPU) # inference time per epoch\n",
    "\n",
    "\n",
    "with open(\"output_2D_spherical_proj_class_norm_per_exp_train_test_IRA_9x16.txt\", \"a\") as f:\n",
    "\n",
    "    print(\"CNN 2D - fold: \", file=f)\n",
    "    print(classification_report(list_test_labels,list_test_predicted,target_names=class_name), file=f)\n",
    "    print(\"Training time per Fold:\", training_time, file=f)\n",
    "    print(\"Inference time per Fold:\", sum_syn, file=f)\n",
    "\n",
    "    print(\"Inference instance:\", len(list_test_predicted), file=f)\n",
    "    print(\"Inference time per instance:\", mean_syn_per_instance, file=f)\n",
    "\n",
    "    print(\"=====CPU=========\", file=f)\n",
    "\n",
    "    print(classification_report(list_test_labels_CPU,list_test_predicted_CPU,target_names=class_name), file=f)\n",
    "    print(\"Inference time per Fold CPU:\", sum_syn_CPU, file=f)\n",
    "    print(\"Inference instance CPU:\", len(list_test_predicted_CPU), file=f)\n",
    "    print(\"Inference time per instance CPU:\", mean_syn_per_instance_CPU, file=f)\n",
    "    \n",
    "    print(\"=================\", file=f)   \n",
    "    \n",
    "print('Accuracy of the network on the %d test images: %d %%' % (num_batches*batch_size,\n",
    "    100 * correct / total))\n",
    "confusion_mtx = confusion_matrix(list_test_labels, list_test_predicted) \n",
    "\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx,class_name) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8LidCov",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
